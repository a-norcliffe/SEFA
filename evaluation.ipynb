{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e5e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as osp\n",
    "os.makedirs(\"plots\", exist_ok=True)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import one_hot\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Path: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d35da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take SEFA results from main and put them in the ablation results.\n",
    "# Take the SEFA beta=0.0, 1 acq_sample, 1 train_sample, latent_dim=1, ablations\n",
    "# and put them in the sensitivity results.\n",
    "# Avoids complex evaluation code and checks.\n",
    "\n",
    "main_folder = osp.join(\"experiments\", \"results\", \"main\")\n",
    "ablation_folder = osp.join(\"experiments\", \"results\", \"ablations\")\n",
    "\n",
    "for dataset in os.listdir(main_folder):\n",
    "  main_results = torch.load(osp.join(main_folder, dataset))\n",
    "  ablation_results = torch.load(osp.join(ablation_folder, dataset))\n",
    "  ablation_results[\"metrics\"][\"sefa\"] = main_results[\"metrics\"][\"sefa\"]\n",
    "  ablation_results[\"selections\"][\"sefa\"] = main_results[\"selections\"][\"sefa\"]\n",
    "  torch.save(ablation_results, osp.join(ablation_folder, dataset))\n",
    "\n",
    "\n",
    "sensitivity_folder = osp.join(\"experiments\", \"results\", \"ablations\", \"sensitivity\")\n",
    "for dataset in [\"syn1\", \"syn2\", \"syn3\"]:\n",
    "  ablation_results = torch.load(osp.join(ablation_folder, f\"{dataset}.pt\"))\n",
    "\n",
    "  acq_sensitivity = torch.load(osp.join(sensitivity_folder, dataset, \"acq_sample.pt\"))\n",
    "  acq_sensitivity[1] = ablation_results[\"selections\"][\"acq_sample\"]\n",
    "  torch.save(acq_sensitivity, osp.join(sensitivity_folder, dataset, \"acq_sample.pt\"))\n",
    "\n",
    "  beta_sensitivity = torch.load(osp.join(sensitivity_folder, dataset, \"beta.pt\"))\n",
    "  beta_sensitivity[\"0_0\"] = ablation_results[\"selections\"][\"beta\"]\n",
    "  torch.save(beta_sensitivity, osp.join(sensitivity_folder, dataset, \"beta.pt\"))\n",
    "\n",
    "  latent_sensitivity = torch.load(osp.join(sensitivity_folder, dataset, \"num_latents.pt\"))\n",
    "  latent_sensitivity[1] = ablation_results[\"selections\"][\"num_latents\"]\n",
    "  torch.save(latent_sensitivity, osp.join(sensitivity_folder, dataset, \"num_latents.pt\"))\n",
    "\n",
    "  train_sensitivity = torch.load(osp.join(sensitivity_folder, dataset, \"train_sample.pt\"))\n",
    "  train_sensitivity[1] = ablation_results[\"selections\"][\"train_sample\"]\n",
    "  torch.save(train_sensitivity, osp.join(sensitivity_folder, dataset, \"train_sample.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af41bc9",
   "metadata": {},
   "source": [
    "# Set up Fonts and Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4665c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set color maps, and fonts.\n",
    "\n",
    "custom_cmap = ListedColormap(matplotlib.colormaps[\"Blues\"](np.linspace(0, 1, 1000))[:900])\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "matplotlib.rcParams[\"mathtext.fontset\"] = \"dejavuserif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e7b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set names for tables and plots.\n",
    "\n",
    "model_names_dict = {\n",
    "  \"acflow\": \"ACFlow\",\n",
    "  \"dime\": \"DIME\",\n",
    "  \"eddi\": \"EDDI\",\n",
    "  \"fixed_mlp\": \"Fixed MLP\",\n",
    "  \"gdfs\": \"GDFS\",\n",
    "  \"gsmrl\": \"GSMRL\",\n",
    "  \"opportunistic\": \"Opportunistic RL\",\n",
    "  \"random\": \"Random\",\n",
    "  \"vae\": \"VAE\",\n",
    "  \"sefa\": \"SEFA (ours)\",\n",
    "}\n",
    "\n",
    "ablations_names_dict = {\n",
    "  \"beta\": \"$\\\\beta = 0$\",\n",
    "  \"acq_sample\": \"1 Acquisition Sample\",\n",
    "  \"train_sample\": \"1 Train Sample\",\n",
    "  \"deterministic\": \"Deterministic Encoder\",\n",
    "  \"num_latents\": \"Latent Dim = 1\",\n",
    "  \"feature_space_ablation\": \"Feature Space\",\n",
    "  \"copula\": \"WO Copula\",\n",
    "  \"no_normalize\": \"WO Normalization\",\n",
    "  \"prob_weighting\": \"WO Prob Weighting\",\n",
    "  \"sefa\": \"SEFA (full)\",\n",
    "}\n",
    "\n",
    "dataset_names_dict = {\n",
    "  \"bank\": \"Bank Marketing\",\n",
    "  \"california_housing\": \"California Housing\",\n",
    "  \"cube\": \"Cube\",\n",
    "  \"fashion_mnist\": \"Fashion MNIST\",\n",
    "  \"metabric\": \"METABRIC\",\n",
    "  \"miniboone\": \"MiniBooNE\",\n",
    "  \"mnist\": \"MNIST\",\n",
    "  \"syn1\": \"Syn1\",\n",
    "  \"syn2\": \"Syn2\",\n",
    "  \"syn3\": \"Syn3\",\n",
    "  \"tcga\": \"TCGA\",\n",
    "}\n",
    "\n",
    "dataset_metrics_dict = {\n",
    "  \"bank\": \"AUROC\",\n",
    "  \"california_housing\": \"Accuracy\",\n",
    "  \"cube\": \"Accuracy\",\n",
    "  \"fashion_mnist\": \"Accuracy\",\n",
    "  \"metabric\": \"Accuracy\",\n",
    "  \"miniboone\": \"AUROC\",\n",
    "  \"mnist\": \"Accuracy\",\n",
    "  \"syn1\": \"AUROC\",\n",
    "  \"syn2\": \"AUROC\",\n",
    "  \"syn3\": \"AUROC\",\n",
    "  \"tcga\": \"Accuracy\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8359001e",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca421ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mean_acquisition_metric_table(table_type, ablation):\n",
    "  first_row = [\"cube\", \"bank\", \"california_housing\", \"miniboone\"]\n",
    "  second_row = [\"mnist\", \"fashion_mnist\", \"metabric\", \"tcga\"]\n",
    "\n",
    "  if ablation:\n",
    "    folder_path = osp.join(\"experiments\", \"results\", \"ablations\")\n",
    "    tmp_model_names = ablations_names_dict\n",
    "    model_ablation = \"Ablation\"\n",
    "  else:\n",
    "    folder_path = osp.join(\"experiments\", \"results\", \"main\")\n",
    "    tmp_model_names = model_names_dict\n",
    "    model_ablation = \"Model\"\n",
    "\n",
    "  # Load in data.\n",
    "  print_data = {}\n",
    "  for dataset in first_row + second_row:\n",
    "    print_data[dataset] = {}\n",
    "    dataset_data = torch.load(osp.join(folder_path, f\"{dataset}.pt\"))[\"metrics\"]\n",
    "    for model in tmp_model_names.keys():\n",
    "      tmp_data = dataset_data[model][:, 1:].numpy()\n",
    "      avg_metric = np.mean(tmp_data, axis=-1)\n",
    "      mean = np.mean(avg_metric)\n",
    "      std_err = np.std(avg_metric, ddof=1) / (len(avg_metric)**0.5)\n",
    "      print_data[dataset][model] = (mean, std_err)\n",
    "\n",
    "  # ~~~~~~~~~~~~~~ Latex Table ~~~~~~~~~~~~~~\n",
    "  if table_type == \"latex\":\n",
    "    print(\"\\\\begin{table}\")\n",
    "    print(\"  \\\\caption{WRITE THIS}\")\n",
    "    print(\"  \\\\label{WRITE_THIS}\")\n",
    "    print(\"  \\\\centering\")\n",
    "    print(\"  \\\\begin{tabular}{\"+\"c\"*(len(first_row)+1)+\"}\")\n",
    "    for row in [first_row, second_row]:\n",
    "      if row == first_row:\n",
    "        print(\"    \\\\toprule\")\n",
    "      elif row == second_row:\n",
    "        print(\"    \\\\midrule\")\n",
    "      print(f\"    {model_ablation}\", end=\"\")\n",
    "      for dataset in row:\n",
    "        print(f\" & {dataset_names_dict[dataset]}\", end=\"\")\n",
    "      print(\" \\\\\\\\\")\n",
    "      print(\"    \\\\midrule\")\n",
    "      for model in tmp_model_names.keys():\n",
    "        print(f\"    {tmp_model_names[model]}\", end=\"\")\n",
    "        for dataset in row:\n",
    "          mean, std_err = print_data[dataset][model]\n",
    "          print(f\" & ${mean:.3f} \\\\pm {std_err:.3f}$\", end=\"\")\n",
    "        print(\" \\\\\\\\\")\n",
    "    print(\"    \\\\bottomrule\")\n",
    "    print(\"  \\\\end{tabular}\")\n",
    "    print(\"\\\\end{table}\")\n",
    "\n",
    "  # ~~~~~~~~~~~~~~ Markdown Table ~~~~~~~~~~~~~~\n",
    "  elif table_type == \"markdown\":\n",
    "    for row in [first_row, second_row]:\n",
    "      print(f\"| {model_ablation} |\", end=\"\")\n",
    "      for dataset in row:\n",
    "        print(f\" {dataset_names_dict[dataset]} |\", end=\"\")\n",
    "      print(\"\")\n",
    "\n",
    "      if row == first_row:\n",
    "        print(\"| --- |\" + \" --- |\"*len(row))\n",
    "\n",
    "      for model in tmp_model_names.keys():\n",
    "        print(f\"| {tmp_model_names[model]} |\", end=\"\")\n",
    "        for dataset in row:\n",
    "          mean, std_err = print_data[dataset][model]\n",
    "          print(f\" ${mean:.3f} \\\\pm {std_err:.3f}$ |\", end=\"\")\n",
    "        print(\"\")\n",
    "\n",
    "      if row == first_row:\n",
    "        print(\"|   |\" + \"   |\"*len(row))\n",
    "\n",
    " # ~~~~~~~~~~~~~~ Python Table ~~~~~~~~~~~~~~\n",
    "  elif table_type == \"python\":\n",
    "    table = []\n",
    "    for row in [first_row, second_row]:\n",
    "      names = [f\"{model_ablation}\"] + [dataset_names_dict[dataset] for dataset in row]\n",
    "      table.append(names)\n",
    "      for model in tmp_model_names.keys():\n",
    "        row_data = [tmp_model_names[model]]\n",
    "        for dataset in row:\n",
    "          mean, std_err = print_data[dataset][model]\n",
    "          row_data.append(f\"{mean:.3f} \\u00B1 {std_err:.3f}\")\n",
    "        table.append(row_data)\n",
    "      if row == first_row:\n",
    "        table.append([\"\"] * len(names))\n",
    "    print(tabulate(table, tablefmt=\"fancy_grid\"))\n",
    "\n",
    "  else:\n",
    "    raise ValueError(f\"Table type {table_type} not recognized. Must be latex, markdown or python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b3e970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main results.\n",
    "print_mean_acquisition_metric_table(table_type=\"latex\", ablation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd64f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablations table.\n",
    "print_mean_acquisition_metric_table(table_type=\"latex\", ablation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64138f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Counts table.\n",
    "\n",
    "def is_mask_complete(mask, known_features):\n",
    "  return torch.all(mask[:, known_features], dim=-1).float().detach().cpu().numpy()\n",
    "\n",
    "\n",
    "def run_once(selections, known_features):\n",
    "  num_features = selections.shape[0]\n",
    "  batch_size = selections.shape[-1]\n",
    "  counts = np.zeros(batch_size)\n",
    "  mask = torch.zeros((batch_size, num_features))\n",
    "\n",
    "  for i in range(num_features):\n",
    "    mask = torch.max(mask, one_hot(selections[i], num_features).float())\n",
    "    counts += (1.0 - is_mask_complete(mask, known_features))\n",
    "  return counts + 1.0  # Add one for the selection that completes mask.\n",
    "\n",
    "\n",
    "def get_syn_results(syn_num, ablation):\n",
    "  if ablation:\n",
    "    folder_path = osp.join(\"experiments\", \"results\", \"ablations\")\n",
    "    tmp_model_names = ablations_names_dict\n",
    "  else:\n",
    "    folder_path = osp.join(\"experiments\", \"results\", \"main\")\n",
    "    tmp_model_names = model_names_dict\n",
    "\n",
    "  selections = torch.load(osp.join(folder_path, f\"syn{syn_num}.pt\"))[\"selections\"]\n",
    "\n",
    "  X_test = torch.load(osp.join(\"datasets\", \"data\", f\"syn{syn_num}\", \"X_test_std.pt\"))\n",
    "  pos_ids = torch.where(X_test[:, -1] >= 0.0)[0]\n",
    "  neg_ids = torch.where(X_test[:, -1] < 0.0)[0]\n",
    "\n",
    "  if syn_num == 1:\n",
    "    neg_features = np.array([0, 1, 10])\n",
    "    pos_features = np.array([2, 3, 4, 5, 10])\n",
    "  elif syn_num == 2:\n",
    "    neg_features = np.array([0, 1, 10])\n",
    "    pos_features = np.array([6, 7, 8, 9, 10])\n",
    "  elif syn_num == 3:\n",
    "    neg_features = np.array([2, 3, 4, 5, 10])\n",
    "    pos_features = np.array([6, 7, 8, 9, 10])\n",
    "  else:\n",
    "    raise ValueError(f\"Unknown synthetic dataset number: {syn_num}, should be 1, 2 or 3.\")\n",
    "\n",
    "  counts = {}\n",
    "\n",
    "  for model_name in tmp_model_names.keys():\n",
    "    model_selections = selections[model_name]\n",
    "    neg_arr = []\n",
    "    pos_arr = []\n",
    "    # Loop over the repeats (can be parallelised but isn't slow so no need).\n",
    "    for rpt in range(len(model_selections)):\n",
    "      neg_arr.append(run_once(model_selections[rpt][:, neg_ids], neg_features))\n",
    "      pos_arr.append(run_once(model_selections[rpt][:, pos_ids], pos_features))\n",
    "    neg_arr = np.stack(neg_arr, axis=0)\n",
    "    pos_arr = np.stack(pos_arr, axis=0)\n",
    "    counts[model_name] = {\"less_than\": neg_arr, \"more_than\": pos_arr}\n",
    "  return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23908047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the main table.\n",
    "\n",
    "def print_syn_acquisition_count_table(table_type, ablation):\n",
    "\n",
    "  if ablation:\n",
    "    tmp_model_names = ablations_names_dict\n",
    "    model_ablation = \"Ablation\"\n",
    "  else:\n",
    "    tmp_model_names = model_names_dict\n",
    "    model_ablation = \"Model\"\n",
    "\n",
    "  # Get dictionary of counts.\n",
    "  syn_counts = {}\n",
    "  for i in [1, 2, 3]:\n",
    "    syn_counts[i] = {}\n",
    "    syn_results = get_syn_results(i, ablation)\n",
    "    for model_name in tmp_model_names.keys():\n",
    "      model_results = syn_results[model_name]\n",
    "      less_results = model_results[\"less_than\"]\n",
    "      more_results = model_results[\"more_than\"]\n",
    "      overall_results = np.concatenate([less_results, more_results], axis=-1)\n",
    "      overall_results = np.mean(overall_results, axis=-1)\n",
    "      overall_mean = np.mean(overall_results)\n",
    "      overall_std_err = np.std(overall_results, ddof=1) /(len(overall_results)**0.5)\n",
    "      syn_counts[i][model_name] = (overall_mean, overall_std_err)\n",
    "\n",
    "  # ~~~~~~~~~~~~~~ Latex Table ~~~~~~~~~~~~~~\n",
    "  if table_type == \"latex\":\n",
    "    print(\"\\\\begin{table}\")\n",
    "    print(\"  \\\\caption{WRITE THIS}\")\n",
    "    print(\"  \\\\label{tbl:WRITE_THIS}\")\n",
    "    print(\"  \\\\centering\")\n",
    "    print(\"  \\\\begin{tabular}{cccc}\")\n",
    "    print(\"    \\\\toprule\")\n",
    "    print(f\"    {model_ablation} & Syn1 & Syn2 & Syn3 \\\\\\\\\")\n",
    "    print(\"    \\\\midrule\")\n",
    "    for model_name in tmp_model_names.keys():\n",
    "      print(f\"    {tmp_model_names[model_name]} \", end=\"\")\n",
    "      for i in [1, 2, 3]:\n",
    "        mean, std_err = syn_counts[i][model_name]\n",
    "        print(f\"& ${mean:.3f} \\\\pm {std_err:.3f}$ \", end=\"\")\n",
    "      print(\"\\\\\\\\\")\n",
    "    print(\"    \\\\bottomrule\")\n",
    "    print(\"  \\\\end{tabular}\")\n",
    "    print(\"\\\\end{table}\")\n",
    "\n",
    "  # ~~~~~~~~~~~~~~ Markdown Table ~~~~~~~~~~~~~~\n",
    "  elif table_type == \"markdown\":\n",
    "    print(f\"| {model_ablation} | Syn1 | Syn2 | Syn3 |\")\n",
    "    print(\"| --- | --- | --- | --- |\")\n",
    "    for model_name in tmp_model_names.keys():\n",
    "      print(f\"| {tmp_model_names[model_name]} |\", end=\"\")\n",
    "      for i in [1, 2, 3]:\n",
    "        mean, std_err = syn_counts[i][model_name]\n",
    "        print(f\" ${mean:.3f} \\\\pm {std_err:.3f}$ |\", end=\"\")\n",
    "      print(\"\")\n",
    "\n",
    "  # ~~~~~~~~~~~~~~ Python Table ~~~~~~~~~~~~~~\n",
    "  elif table_type == \"python\":\n",
    "    table = [[f\"{model_ablation}\", \"Syn1\", \"Syn2\", \"Syn3\"]]\n",
    "    for model_name in tmp_model_names.keys():\n",
    "      row = [tmp_model_names[model_name]]\n",
    "      for i in [1, 2, 3]:\n",
    "        mean, std_err = syn_counts[i][model_name]\n",
    "        row.append(f\"{mean:.3f} \\u00B1 {std_err:.3f}\")\n",
    "      table.append(row)\n",
    "    print(tabulate(table, tablefmt=\"fancy_grid\"))\n",
    "  \n",
    "  else:\n",
    "    raise ValueError(f\"Table type {table_type} not recognized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7feac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_syn_acquisition_count_table(table_type=\"latex\", ablation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f658afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_syn_acquisition_count_table(table_type=\"latex\", ablation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93ab815",
   "metadata": {},
   "source": [
    "# Acquisition Trajectories Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cad67cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In format [left most location, top most location].\n",
    "\n",
    "axin_positions = {\n",
    "  \"cube\": [0.35, 0.72],\n",
    "  \"bank\": [0.35, 0.65],\n",
    "  \"california_housing\": [0.44, 0.54],\n",
    "  \"miniboone\": [0.32, 0.72],\n",
    "  \"mnist\": [0.45, 0.65],\n",
    "  \"fashion_mnist\": [0.38, 0.75],\n",
    "  \"metabric\": [0.42, 0.64],\n",
    "  \"tcga\": [0.4, 0.71],\n",
    "}\n",
    "\n",
    "axin_ylims = {\n",
    "  \"cube\": [0.96, 0.967],\n",
    "  \"bank\": [0.90, 0.94],\n",
    "  \"california_housing\": [0.63, 0.76],\n",
    "  \"miniboone\": [0.960, 0.977],\n",
    "  \"mnist\": [0.75, 0.92],\n",
    "  \"fashion_mnist\": [0.72, 0.81],\n",
    "  \"metabric\": [0.70, 0.772],\n",
    "  \"tcga\": [0.87, 0.935],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da51d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_on_axis(ax, dataset, trajectories_model_list, ablation):\n",
    "  if ablation:\n",
    "    data_path = osp.join(\"experiments\", \"results\", \"ablations\")\n",
    "    tmp_model_names = ablations_names_dict\n",
    "  else:\n",
    "    data_path = osp.join(\"experiments\", \"results\", \"main\")\n",
    "    tmp_model_names = model_names_dict\n",
    "\n",
    "  # Insert sub axis.\n",
    "  axin_lh = axin_positions[dataset]\n",
    "  bottom_axin = 0.1\n",
    "  axin = ax.inset_axes([axin_lh[0], bottom_axin, 0.98-axin_lh[0], axin_lh[1]-bottom_axin])\n",
    "\n",
    "  markers = [\"o\", \"s\", \"D\", \"^\", \"P\"]\n",
    "  marker_id = 0\n",
    "\n",
    "  plot_data = torch.load(osp.join(data_path, f\"{dataset}.pt\"))[\"metrics\"]\n",
    "\n",
    "  for model in trajectories_model_list:\n",
    "    tmp_data = plot_data[model][:, 1:].numpy()\n",
    "    num_features = tmp_data.shape[-1]\n",
    "    mean = np.mean(tmp_data, axis=0)  # Mean and error taken across repeats.\n",
    "    err = np.std(tmp_data, axis=0, ddof=1) / (len(tmp_data)**0.5)\n",
    "    x = np.arange(num_features)+1\n",
    "    ax.plot(x, mean, label=tmp_model_names[model], marker=markers[marker_id], markersize=6, linestyle=\"-.\")\n",
    "    ax.fill_between(x, mean-err, mean+err, alpha=0.4)\n",
    "    axin.plot(x, mean, marker=markers[marker_id], markersize=6, linestyle=\"-.\")\n",
    "    axin.fill_between(x, mean-err, mean+err, alpha=0.4)\n",
    "    marker_id = (marker_id+1)%len(markers)\n",
    "\n",
    "  # Ticks and limits\n",
    "  if num_features > 16:\n",
    "    ticks = np.arange(0, num_features+1, 2)\n",
    "  else:\n",
    "    ticks = np.arange(0, num_features+1)\n",
    "\n",
    "  ax.tick_params(axis=\"both\", labelsize=11)\n",
    "  ax.set_xticks(ticks)\n",
    "  ax.set_xlim(0.4, num_features+0.6)\n",
    "  ax.grid()\n",
    "\n",
    "  start_feature = int(num_features/3)\n",
    "  axin.tick_params(axis=\"both\", labelsize=9)\n",
    "  axin.set_xticks(ticks)\n",
    "  axin.set_xlim(start_feature-0.4, num_features+0.4)\n",
    "  axin.set_ylim(*axin_ylims[dataset])\n",
    "  axin.grid()\n",
    "\n",
    "  # Titles and axis labels\n",
    "  ax.set_title(dataset_names_dict[dataset], fontsize=19)\n",
    "  ax.set_xlabel(\"Acquisition No.\", fontsize=14)\n",
    "  ax.set_ylabel(dataset_metrics_dict[dataset], fontsize=14)\n",
    "\n",
    "\n",
    "\n",
    "def make_trajectories_plots(trajectories_dataset_list, trajectories_model_list, ablation):\n",
    "  tmp_model_names = ablations_names_dict if ablation else model_names_dict\n",
    "  fig, ax = plt.subplots(nrows=2, ncols=4, figsize=[18, 6.5])\n",
    "  for i, dataset in enumerate(trajectories_dataset_list):\n",
    "    plot_on_axis(ax.flatten()[i], dataset, trajectories_model_list, ablation)\n",
    "  fig.tight_layout()\n",
    "  lines= ax.flatten()[-1].get_lines()\n",
    "  labels = [tmp_model_names[m] for m in trajectories_model_list]\n",
    "  fig.legend(lines, labels, loc=\"upper center\", bbox_to_anchor=(0.5, -0.005), ncol=len(trajectories_model_list), fontsize=13)\n",
    "\n",
    "  plt.savefig(osp.join(\"plots\", f\"trajectories{'_ablation' if ablation else ''}.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f3f2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories_dataset_list = [\n",
    "  \"cube\", \"bank\", \"california_housing\", \"miniboone\", \n",
    "  \"mnist\", \"fashion_mnist\", \"metabric\", \"tcga\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_trajectories_plots(\n",
    "  trajectories_dataset_list=trajectories_dataset_list,\n",
    "  trajectories_model_list=[\"sefa\", \"dime\", \"fixed_mlp\", \"gdfs\", \"opportunistic\"],\n",
    "  ablation=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b4f247",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_trajectories_plots(\n",
    "  trajectories_dataset_list=trajectories_dataset_list,\n",
    "  trajectories_model_list=[\"sefa\", \"prob_weighting\", \"deterministic\", \"acq_sample\", \"train_sample\"],\n",
    "  ablation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775379c",
   "metadata": {},
   "source": [
    "# Heat Maps of Individual Acquisition Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df16f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle_axis(ax, left, down, right, up, linestyle=\"-\", color=\"lime\"):\n",
    "  ax.plot([left, right], [up, up], color=color, linestyle=linestyle)\n",
    "  ax.plot([left, right], [down, down], color=color, linestyle=linestyle)\n",
    "  ax.plot([left, left], [up, down], color=color, linestyle=linestyle)\n",
    "  ax.plot([right, right], [up, down], color=color, linestyle=linestyle)\n",
    "\n",
    "\n",
    "def hm_trajectories_on_axis(ax, selections, aspect=0.4, max_features=6, max_trajectories=5, weight=0.015, feature_labels=None):\n",
    "  # HM means heatmap, so we have a heat map behind sample trajectories.\n",
    "  np.random.seed(7819)\n",
    "  selections = selections.numpy()  # Shape: [repeat, num_features, batch]\n",
    "  num_features = selections.shape[1]\n",
    "  hm = []\n",
    "  for f in range(num_features):\n",
    "    hm.append(np.mean(selections == f, axis=(0, 2)))\n",
    "  hm = np.stack(hm, axis=0)\n",
    "  ax.imshow(hm, cmap=custom_cmap, aspect=aspect, origin=\"lower\", vmin=0.0, vmax=1.0)\n",
    "\n",
    "  trajectories = np.reshape(np.transpose(selections, (1, 0, 2)), (num_features, -1))  # Just flattens trajectories across repeats and batches.\n",
    "  trajectories = trajectories[:, np.random.permutation(trajectories.shape[1])]\n",
    "  max_trajectories = min(max_trajectories, trajectories.shape[1])\n",
    "  trajectories = trajectories[:max_features, :max_trajectories]\n",
    "  alpha = weight*500/max_trajectories\n",
    "  ax.plot(trajectories, color=\"red\", linewidth=2.5, alpha=alpha)\n",
    "  ax.set_xlim(-0.5, max_features-0.5)\n",
    "  ax.set_xticks(ticks=np.arange(max_features), labels=np.arange(max_features)+1)\n",
    "  if feature_labels is None:\n",
    "    feature_labels = np.arange(num_features)+1\n",
    "  ax.set_yticks(ticks=np.arange(num_features), labels=feature_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e72ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_syn_heatmap(syn_num, model_list, ablation):\n",
    "  if ablation:\n",
    "    tmp_model_names = ablations_names_dict\n",
    "    selection_path = osp.join(\"experiments\", \"results\", \"ablations\")\n",
    "  else:\n",
    "    tmp_model_names = model_names_dict\n",
    "    selection_path = osp.join(\"experiments\", \"results\", \"main\")\n",
    "\n",
    "  syn_x = torch.load(osp.join(\"datasets\", \"data\", f\"syn{syn_num}\", \"X_test_std.pt\"))\n",
    "  less_ids = torch.where(syn_x[:, -1] < 0.0)[0]\n",
    "  more_ids = torch.where(syn_x[:, -1] >= 0.0)[0]\n",
    "\n",
    "  fig, ax = plt.subplots(nrows=2, ncols=len(model_list), figsize=[4*len(model_list), 6.5])\n",
    "  all_selections = torch.load(osp.join(selection_path, f\"syn{syn_num}.pt\"))[\"selections\"]\n",
    "\n",
    "  for m, model in enumerate(model_list):\n",
    "    selections = all_selections[model]\n",
    "\n",
    "    hm_trajectories_on_axis(ax[0, m], selections[:, :, less_ids], max_trajectories=400)\n",
    "    hm_trajectories_on_axis(ax[1, m], selections[:, :, more_ids], max_trajectories=400)\n",
    "\n",
    "    # Rectangles on feature 11 first. Then on remaining features.\n",
    "    draw_rectangle_axis(ax[0, m], -0.5, 9.5, 0.5, 10.5)\n",
    "    draw_rectangle_axis(ax[1, m], -0.5, 9.5, 0.5, 10.5)\n",
    "    if syn_num == 1:\n",
    "      draw_rectangle_axis(ax[0, m], 0.5, -0.5, 2.5, 1.5)\n",
    "      ax[0, m].axvline(x=2.5, color=\"black\", linestyle=\"--\")\n",
    "      draw_rectangle_axis(ax[1, m], 0.5, 1.5, 4.5, 5.5)\n",
    "      ax[1, m].axvline(x=4.5, color=\"black\", linestyle=\"--\")\n",
    "    elif syn_num == 2:\n",
    "      draw_rectangle_axis(ax[0, m], 0.5, -0.5, 2.5, 1.5)\n",
    "      ax[0, m].axvline(x=2.5, color=\"black\", linestyle=\"--\")\n",
    "      draw_rectangle_axis(ax[1, m], 0.5, 5.5, 4.5, 9.5)\n",
    "      ax[1, m].axvline(x=4.5, color=\"black\", linestyle=\"--\")\n",
    "    elif syn_num == 3:\n",
    "      draw_rectangle_axis(ax[0, m], 0.5, 1.5, 4.5, 5.5)\n",
    "      ax[0, m].axvline(x=4.5, color=\"black\", linestyle=\"--\")\n",
    "      draw_rectangle_axis(ax[1, m], 0.5, 5.5, 4.5, 9.5)\n",
    "      ax[1, m].axvline(x=4.5, color=\"black\", linestyle=\"--\")\n",
    "    else:\n",
    "      raise ValueError(f\"Unknown synthetic dataset number: {syn_num}, should be 1, 2 or 3.\")\n",
    "\n",
    "    ax[0, m].tick_params(axis=\"both\", labelsize=12)\n",
    "    ax[1, m].tick_params(axis=\"both\", labelsize=12)\n",
    "    ax[0, m].set_title(f\"{tmp_model_names[model]} \" + r\"$x_{11} < 0.0$\", fontsize=15)\n",
    "    ax[1, m].set_title(f\"{tmp_model_names[model]} \" + r\"$x_{11} \\geq 0.0$\", fontsize=15)\n",
    "\n",
    "  fig.supxlabel(\"Acquisition\", fontsize=18, y=0.05)\n",
    "  fig.supylabel(\"Feature\", fontsize=18, x=0.09)\n",
    "  fig.suptitle(f\"Syn{syn_num} Acquisition Proportions and Trajectories\", y=0.96, fontsize=22)\n",
    "\n",
    "  cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "  cbar = fig.colorbar(ax[0, 0].get_images()[0], cax=cbar_ax)\n",
    "  cbar.ax.set_yticks(ticks=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=[0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=12)\n",
    "  cbar_ax.set_ylabel(\"Acquisition Proportions\", fontsize=18)\n",
    "\n",
    "  plt.savefig(osp.join(\"plots\", f\"syn{syn_num}_heatmap{'_ablation' if ablation else ''}.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0513d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main heatmaps for synthetic datasets.\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "  full_syn_heatmap(i, model_list=[\"sefa\", \"opportunistic\", \"dime\", \"gdfs\"], ablation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b426a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ablation heatmaps.\n",
    "\n",
    "for i in [1, 2, 3]:\n",
    "  full_syn_heatmap(i, model_list=[\"sefa\", \"feature_space_ablation\", \"deterministic\", \"acq_sample\"], ablation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1d04a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TCGA heatmaps\n",
    "\n",
    "tumor_names = {\n",
    "  0: \"Breast\",\n",
    "  1: \"Lung\",\n",
    "  2: \"Kidney\",\n",
    "  3: \"Brain\",\n",
    "  4: \"Ovary\",\n",
    "  5: \"Endometrium\",\n",
    "  6: \"Head and Neck\",\n",
    "  7: \"Central Nervous System\",\n",
    "  8: \"Thyroid\",\n",
    "  9: \"Prostate\",\n",
    "  10: \"Colon\",\n",
    "  11: \"Stomach\",\n",
    "  12: \"Bladder\",\n",
    "  13: \"Liver\",\n",
    "  14: \"Cervix\",\n",
    "  15: \"Bone Marrow\",\n",
    "  16: \"Pancreas\",\n",
    "}\n",
    "\n",
    "ordered_tcga_class_genes = {\n",
    "  \"Breast\": [[1, \"ST6GAL1\"], [2, \"DEF6\"], [3, \"C7orf51\"]],\n",
    "  \"Lung\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"PON3\"]],\n",
    "  \"Kidney\": [[1, \"ST6GAL1\"], [2, \"POU3F3\"], [3, \"KAAG1\"], [4, \"HOXA9\"]],\n",
    "  \"Brain\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"DEF6\"]],\n",
    "  \"Ovary\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"KAAG1\"]],\n",
    "  \"Endometrium\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"LYPLAL1\"], [4, \"PON3\"]],\n",
    "  \"Head and Neck\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"GRIA2\"], [4, \"HOXA9\"]],\n",
    "  \"Central Nervous System\": [[1, \"ST6GAL1\"], [2, \"PON3\"], [3, \"SERPINB1\"]],\n",
    "  \"Thyroid\": [[1, \"ST6GAL1\"], [2, \"PON3\"], [3, \"FOXE1\"]],\n",
    "  \"Prostate\": [[1, \"ST6GAL1\"], [2, \"SERPINB1\"], [3, \"GRIA2\"]],\n",
    "  \"Colon\": [[1, \"ST6GAL1\"], [2, \"SERPINB1\"], [3, \"LYPLAL1\"], [4, \"HOXA9\"]],\n",
    "  \"Stomach\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"LYPLAL1\"]],\n",
    "  \"Bladder\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"TMEM106A\"]],\n",
    "  \"Liver\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"PON3\"]],\n",
    "  \"Cervix\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"GRIA2\"]],\n",
    "  \"Bone Marrow\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"DEF6\"], [4, \"GPR81\"]],\n",
    "  \"Pancreas\": [[1, \"ST6GAL1\"], [2, \"DNASE1L3\"], [3, \"LYPLAL1\"], [4, \"C7orf51\"]],\n",
    "}\n",
    "\n",
    "tcga_feature_labels = [\n",
    "  \"C7orf51\",\n",
    "  \"DEF6\",\n",
    "  \"DNASE1L3\",\n",
    "  \"EFS\",\n",
    "  \"FOXE1\",\n",
    "  \"GPR81\",\n",
    "  \"GRIA2\",\n",
    "  \"GSDMC\",\n",
    "  \"HOXA9\",\n",
    "  \"KAAG1\",\n",
    "  \"KLF5\",\n",
    "  \"LOC283392\",\n",
    "  \"LTBR\",\n",
    "  \"LYPLAL1\",\n",
    "  \"PON3\",\n",
    "  \"POU3F3\",\n",
    "  \"SERPINB1\",\n",
    "  \"ST6GAL1\",\n",
    "  \"TMEM106A\",\n",
    "  \"ZNF583\",\n",
    "  \"ZNF790\",\n",
    "]\n",
    "\n",
    "\n",
    "def tcga_large_heatmap(tcga_feature_labels, reduced):\n",
    "  selections = torch.load(osp.join(\"experiments\", \"results\", \"main\", \"tcga.pt\"))[\"selections\"][\"sefa\"]\n",
    "  tcga_y = torch.load(osp.join(\"datasets\", \"data\", \"tcga\", \"y_test.pt\"))\n",
    "\n",
    "  if reduced:\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 5))\n",
    "    classes = [0, 1, 9, 13]\n",
    "    aspect = 0.5\n",
    "  else:\n",
    "    fig, ax = plt.subplots(nrows=4, ncols=5, figsize=(16, 24))\n",
    "    classes = list(range(17))\n",
    "    aspect = 0.8\n",
    "\n",
    "  for i, c in enumerate(classes):\n",
    "    ids = torch.where(tcga_y == c)[0]\n",
    "    hm_trajectories_on_axis(ax.flatten()[i], selections[:, :, ids], aspect=aspect, max_trajectories=100, weight=0.008, feature_labels=tcga_feature_labels)\n",
    "    ax.flatten()[i].set_title(tumor_names[c], fontsize=18 if reduced else 16)\n",
    "\n",
    "    # Draw bounding boxes.\n",
    "    for relevant_feature in ordered_tcga_class_genes[tumor_names[c]]:\n",
    "      acquisition_count = relevant_feature[0]\n",
    "      feature_id = tcga_feature_labels.index(relevant_feature[1])\n",
    "      draw_rectangle_axis(ax.flatten()[i], left=acquisition_count-1.5, down=feature_id-0.5, right=acquisition_count-0.5, up=feature_id+0.5, linestyle=\"-\", color=\"lime\")\n",
    "\n",
    "  if not reduced:\n",
    "    ax[-1, -3].set_axis_off()\n",
    "    ax[-1, -2].set_axis_off()\n",
    "    ax[-1, -1].set_axis_off()\n",
    "\n",
    "  if reduced:\n",
    "    fig.supxlabel(\"Acquistions\", fontsize=18, y=0.01)\n",
    "    fig.supylabel(\"Features\", fontsize=18, x=0.05)\n",
    "  else:\n",
    "    fig.supxlabel(\"Acquistions\", fontsize=22, y=0.08)\n",
    "    fig.supylabel(\"Features\", fontsize=22, x=0.06)\n",
    "\n",
    "  cbar_ax = fig.add_axes([0.92, 0.15, 0.02, 0.7])\n",
    "  if reduced:\n",
    "    cbar = fig.colorbar(ax[0].get_images()[0], cax=cbar_ax)\n",
    "  else:\n",
    "    cbar = fig.colorbar(ax[0, 0].get_images()[0], cax=cbar_ax)\n",
    "  cbar.ax.set_yticks(ticks=[0, 0.2, 0.4, 0.6, 0.8, 1.0], labels=[0, 0.2, 0.4, 0.6, 0.8, 1.0], fontsize=14)\n",
    "  cbar_ax.set_ylabel(\"Acquisition Proportions\", fontsize=22)\n",
    "\n",
    "  plt.savefig(osp.join(\"plots\", f\"tcga_{'reduced' if reduced else 'full'}.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258d1793",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_large_heatmap(tcga_feature_labels, reduced=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27351996",
   "metadata": {},
   "outputs": [],
   "source": [
    "tcga_large_heatmap(tcga_feature_labels, reduced=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba00ec5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c1c8b4a",
   "metadata": {},
   "source": [
    "## Sensitivity Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04e0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_syn_sensitivity_results(x, ablation):\n",
    "  all_selections = torch.load(osp.join(\"experiments\", \"results\", \"ablations\", \"sensitivity\", f\"syn{x}\", f\"{ablation}.pt\"))\n",
    "  X_test = torch.load(osp.join(\"datasets\", \"data\", f\"syn{x}\", \"X_test_std.pt\"))\n",
    "\n",
    "  pos_ids = torch.where(X_test[:, -1] >= 0.0)[0]\n",
    "  neg_ids = torch.where(X_test[:, -1] < 0.0)[0]\n",
    "\n",
    "  if x == 1:\n",
    "    neg_features = np.array([0, 1, 10])\n",
    "    pos_features = np.array([2, 3, 4, 5, 10])\n",
    "  elif x == 2:\n",
    "    neg_features = np.array([0, 1, 10])\n",
    "    pos_features = np.array([6, 7, 8, 9, 10])\n",
    "  elif x == 3:\n",
    "    neg_features = np.array([2, 3, 4, 5, 10])\n",
    "    pos_features = np.array([6, 7, 8, 9, 10])\n",
    "  else:\n",
    "    raise ValueError(f\"Unknown synthetic dataset number: {x}, should be 1, 2 or 3.\")\n",
    "\n",
    "  counts = {}\n",
    "  for sensitivity_value in all_selections.keys():\n",
    "    selections = all_selections[sensitivity_value]\n",
    "    neg_arr = []\n",
    "    pos_arr = []\n",
    "    for rpt in range(len(selections)):\n",
    "      neg_arr.append(run_once(selections[rpt][:, neg_ids], neg_features))\n",
    "      pos_arr.append(run_once(selections[rpt][:, pos_ids], pos_features))\n",
    "    neg_arr = np.stack(neg_arr, axis=0)\n",
    "    pos_arr = np.stack(pos_arr, axis=0)\n",
    "    counts[sensitivity_value] = np.concatenate([neg_arr, pos_arr], axis=-1)\n",
    "  return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ce0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sensitivity_plot(ablation):\n",
    "  syn_counts = {\n",
    "    \"syn1\": create_syn_sensitivity_results(1, ablation),\n",
    "    \"syn2\": create_syn_sensitivity_results(2, ablation),\n",
    "    \"syn3\": create_syn_sensitivity_results(3, ablation),\n",
    "  }\n",
    "\n",
    "  fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(18, 5))\n",
    "\n",
    "  for i in range(3):\n",
    "    means = []\n",
    "    errs = []\n",
    "    x = []\n",
    "    counts = syn_counts[f\"syn{i+1}\"]\n",
    "    for x_value in counts.keys():\n",
    "      results = counts[x_value]\n",
    "      results = np.mean(results, axis=-1)\n",
    "      mean = np.mean(results)\n",
    "      err = np.std(results, ddof=1)/(len(results)**0.5)\n",
    "      means.append(mean)\n",
    "      errs.append(err)\n",
    "      if ablation == \"beta\":\n",
    "        x_value = x_value.replace(\"_\", \".\")\n",
    "      x.append(float(x_value))\n",
    "\n",
    "    x = np.array(x)\n",
    "    sorted_ids = np.argsort(x)\n",
    "    x = x[sorted_ids]\n",
    "    means = np.array(means)[sorted_ids]\n",
    "    errs = np.array(errs)[sorted_ids]\n",
    "\n",
    "    ax[i].fill_between(x, means-errs, means+errs, alpha=0.3, color=\"tab:blue\")\n",
    "    ax[i].plot(x, means, linewidth=2, color=\"tab:blue\", linestyle=\"--\", marker=\"o\", markersize=8)\n",
    "    if ablation == \"beta\":\n",
    "      ax[i].set_xscale('symlog', linthresh=0.000001)\n",
    "      ax[i].set_xlabel(r\"$\\beta$\", fontsize=20)\n",
    "    elif ablation == \"acq_sample\":\n",
    "      ax[i].set_xscale(\"log\")\n",
    "      ax[i].set_xlabel(f\"No. Acquisition Samples\", fontsize=15)\n",
    "    elif ablation == \"train_sample\":\n",
    "      ax[i].set_xscale(\"log\")\n",
    "      ax[i].set_xlabel(f\"No. Training Samples\", fontsize=15)\n",
    "    elif ablation == \"num_latents\":\n",
    "      if i == 0:\n",
    "        ax[i].set_ylim([3.9, 4.3])\n",
    "      if i == 1:\n",
    "        ax[i].set_ylim([3.9, 4.3])\n",
    "      if i == 2:\n",
    "        ax[i].set_ylim([5.0, 5.8])\n",
    "      ax[i].set_xlabel(f\"No. Latent Components\", fontsize=15)\n",
    "    ax[i].set_title(f\"Syn{i+1}\", fontsize=20)\n",
    "    ax[i].set_ylabel(\"Required No. Acquisitions\", fontsize=15)\n",
    "    ax[i].grid()\n",
    "    ax[i].tick_params(axis=\"both\", labelsize=12)\n",
    "\n",
    "  plt.savefig(osp.join(\"plots\", f\"{ablation}_sensitivity.pdf\"), bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5cac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_sensitivity_plot(\"beta\")\n",
    "make_sensitivity_plot(\"acq_sample\")\n",
    "make_sensitivity_plot(\"train_sample\")\n",
    "make_sensitivity_plot(\"num_latents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df889681",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afa_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
